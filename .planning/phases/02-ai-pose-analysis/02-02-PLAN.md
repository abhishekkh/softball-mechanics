---
phase: 02-ai-pose-analysis
plan: 02
type: execute
wave: 2
depends_on: [02-01]
files_modified:
  - src/lib/pose/landmarks.ts
  - src/lib/pose/angles.ts
  - src/lib/pose/flags.ts
  - src/workers/pose-analyzer.worker.ts
autonomous: true
requirements: [AI-01, AI-02, AI-03]

must_haves:
  truths:
    - "angleBetweenThreePoints returns a degree value between 0 and 180"
    - "computeElbowSlot, computeShoulderTilt, computeHipRotation return null when any required landmark visibility < 0.65"
    - "flagMechanics returns MechanicsFlag[] with correct issue labels and confidence values"
    - "pose-analyzer.worker.ts initializes PoseLandmarker using local /mediapipe/wasm path (not CDN)"
    - "drawSkeleton uses ZONE_COLORS — blue for lower body, green for upper body, red for flagged joints"
  artifacts:
    - path: "src/lib/pose/landmarks.ts"
      provides: "ZONE_COLORS, LOWER_BODY_INDICES, drawSkeleton function"
      exports: ["ZONE_COLORS", "LOWER_BODY_INDICES", "drawSkeleton"]
    - path: "src/lib/pose/angles.ts"
      provides: "Joint angle computation functions"
      exports: ["angleBetweenThreePoints", "computeElbowSlot", "computeShoulderTilt", "computeHipRotation"]
    - path: "src/lib/pose/flags.ts"
      provides: "Rule-based mechanics flagging"
      exports: ["flagMechanics", "IDEAL_RANGES"]
    - path: "src/workers/pose-analyzer.worker.ts"
      provides: "Comlink-wrapped MediaPipe PoseLandmarker Web Worker"
      contains: "Comlink.expose"
  key_links:
    - from: "src/workers/pose-analyzer.worker.ts"
      to: "src/lib/pose/* (NO @/ imports)"
      via: "Worker imports only npm packages; pose lib imported by hook instead"
      pattern: "Comlink.expose"
    - from: "src/lib/pose/angles.ts"
      to: "src/lib/pose/flags.ts"
      via: "flagMechanics calls angle values passed in"
      pattern: "flagMechanics"
---

<objective>
Build the pose analysis engine: pure-function libraries for angle computation and mechanics flagging, the canvas skeleton drawing utility, and the Web Worker that runs MediaPipe PoseLandmarker for per-frame inference.

Purpose: This is the compute core. The hook (Plan 03) orchestrates these. Components (Plan 04) display results. Everything in this plan is pure logic with no React or Next.js dependencies.
Output: src/lib/pose/*.ts (angles, flags, landmarks), src/workers/pose-analyzer.worker.ts.
</objective>

<execution_context>
@/Users/abhishekhodavdekar/.claude/get-shit-done/workflows/execute-plan.md
@/Users/abhishekhodavdekar/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/phases/02-ai-pose-analysis/02-RESEARCH.md
@.planning/phases/02-ai-pose-analysis/02-01-SUMMARY.md

<interfaces>
<!-- Types from Plan 01 (src/types/analysis.ts) needed here -->
```typescript
export interface NormalizedLandmark {
  x: number; y: number; z: number; visibility: number
}

export interface MechanicsFlag {
  issue: string
  confidence: number   // 0–1
  severity: 'warning' | 'error'
  jointIndices: number[]
}

export interface FrameAngles {
  elbowSlotDeg: number | null
  shoulderTiltDeg: number | null
  hipRotationDeg: number | null
}
```
</interfaces>
</context>

<tasks>

<task type="auto">
  <name>Task 1: Pose library — landmarks, angles, and flags</name>
  <files>
    src/lib/pose/landmarks.ts
    src/lib/pose/angles.ts
    src/lib/pose/flags.ts
  </files>
  <action>
**Create src/lib/pose/landmarks.ts**

```typescript
// src/lib/pose/landmarks.ts
// MediaPipe PoseLandmarker: 33 landmarks, 0-indexed
// Reference: https://ai.google.dev/edge/mediapipe/solutions/vision/pose_landmarker

import type { NormalizedLandmark } from '@/types/analysis'

// Zone classification: indices >= 23 are lower body (hips, knees, ankles, feet)
export const LOWER_BODY_INDICES = new Set([23, 24, 25, 26, 27, 28, 29, 30, 31, 32])

export const ZONE_COLORS = {
  lower: '#3B82F6',    // blue — hips, knees, ankles
  upper: '#10B981',    // green — shoulders, elbows, wrists
  flagged: '#EF4444',  // red — joints involved in a mechanics flag
} as const

// Visibility threshold: landmarks below this are excluded from drawing and angle computation
export const VISIBILITY_THRESHOLD = 0.65

// Landmark index reference (RHH — right-handed hitter)
// Mirror to 11/13/15 for left-handed hitter
export const LANDMARK_INDICES = {
  LEFT_SHOULDER: 11,
  RIGHT_SHOULDER: 12,
  LEFT_ELBOW: 13,
  RIGHT_ELBOW: 14,
  LEFT_WRIST: 15,
  RIGHT_WRIST: 16,
  LEFT_HIP: 23,
  RIGHT_HIP: 24,
  LEFT_KNEE: 25,
  RIGHT_KNEE: 26,
  LEFT_ANKLE: 27,
  RIGHT_ANKLE: 28,
} as const

/**
 * Draws the MediaPipe pose skeleton onto a Canvas 2D context.
 * Uses PoseLandmarker.POSE_CONNECTIONS for bone connectivity.
 * Skips landmarks with visibility < VISIBILITY_THRESHOLD.
 */
export function drawSkeleton(
  ctx: CanvasRenderingContext2D,
  landmarks: NormalizedLandmark[],
  canvasWidth: number,
  canvasHeight: number,
  flaggedIndices: Set<number> = new Set()
): void {
  if (!landmarks || landmarks.length === 0) return

  const toPixel = (lm: NormalizedLandmark) => ({
    px: lm.x * canvasWidth,
    py: lm.y * canvasHeight,
  })

  // POSE_CONNECTIONS is available on the PoseLandmarker class from @mediapipe/tasks-vision
  // We define the 35 standard connections here to avoid importing the full library in this utility file
  const POSE_CONNECTIONS: [number, number][] = [
    [0,1],[1,2],[2,3],[3,7],[0,4],[4,5],[5,6],[6,8],
    [9,10],[11,12],[11,13],[13,15],[15,17],[15,19],[15,21],
    [17,19],[12,14],[14,16],[16,18],[16,20],[16,22],[18,20],
    [11,23],[12,24],[23,24],[23,25],[25,27],[27,29],[29,31],
    [27,31],[24,26],[26,28],[28,30],[30,32],[28,32],
  ]

  ctx.lineWidth = 3

  // Draw bones
  for (const [start, end] of POSE_CONNECTIONS) {
    const a = landmarks[start]
    const b = landmarks[end]
    if (!a || !b) continue
    if ((a.visibility ?? 1) < VISIBILITY_THRESHOLD || (b.visibility ?? 1) < VISIBILITY_THRESHOLD) continue

    const isFlagged = flaggedIndices.has(start) || flaggedIndices.has(end)
    const isLower = LOWER_BODY_INDICES.has(start) || LOWER_BODY_INDICES.has(end)

    ctx.strokeStyle = isFlagged
      ? ZONE_COLORS.flagged
      : isLower ? ZONE_COLORS.lower : ZONE_COLORS.upper

    const { px: ax, py: ay } = toPixel(a)
    const { px: bx, py: by } = toPixel(b)
    ctx.beginPath()
    ctx.moveTo(ax, ay)
    ctx.lineTo(bx, by)
    ctx.stroke()
  }

  // Draw joint dots
  for (let i = 0; i < landmarks.length; i++) {
    const lm = landmarks[i]
    if ((lm.visibility ?? 1) < VISIBILITY_THRESHOLD) continue
    const { px, py } = toPixel(lm)
    ctx.fillStyle = flaggedIndices.has(i) ? ZONE_COLORS.flagged : '#FFFFFF'
    ctx.beginPath()
    ctx.arc(px, py, 5, 0, 2 * Math.PI)
    ctx.fill()
  }
}
```

**Create src/lib/pose/angles.ts**

```typescript
// src/lib/pose/angles.ts
// Joint angle computation using 3-point vector math
// Source: MDN Math.atan2 + biomechanics research pattern

import { LANDMARK_INDICES, VISIBILITY_THRESHOLD } from './landmarks'
import type { NormalizedLandmark, FrameAngles } from '@/types/analysis'

interface Point { x: number; y: number }

/**
 * Computes the angle (degrees) at joint B given A-B-C landmark triplet.
 * Returns value in range [0, 180].
 */
export function angleBetweenThreePoints(A: Point, B: Point, C: Point): number {
  const BA = { x: A.x - B.x, y: A.y - B.y }
  const BC = { x: C.x - B.x, y: C.y - B.y }

  const dot = BA.x * BC.x + BA.y * BC.y
  const magBA = Math.sqrt(BA.x ** 2 + BA.y ** 2)
  const magBC = Math.sqrt(BC.x ** 2 + BC.y ** 2)

  if (magBA === 0 || magBC === 0) return 0

  // Clamp to [-1, 1] to guard against floating point drift past acos domain
  const cosTheta = Math.max(-1, Math.min(1, dot / (magBA * magBC)))
  return Math.acos(cosTheta) * (180 / Math.PI)
}

/**
 * Elbow slot: angle at elbow (shoulder → elbow → wrist).
 * Uses right side (RHH). Returns null if any landmark visibility < threshold.
 */
export function computeElbowSlot(
  landmarks: NormalizedLandmark[],
  handedness: 'right' | 'left' = 'right'
): number | null {
  const { LEFT_SHOULDER, RIGHT_SHOULDER, LEFT_ELBOW, RIGHT_ELBOW, LEFT_WRIST, RIGHT_WRIST } = LANDMARK_INDICES
  const [shoulderIdx, elbowIdx, wristIdx] = handedness === 'right'
    ? [RIGHT_SHOULDER, RIGHT_ELBOW, RIGHT_WRIST]
    : [LEFT_SHOULDER, LEFT_ELBOW, LEFT_WRIST]

  const s = landmarks[shoulderIdx]
  const e = landmarks[elbowIdx]
  const w = landmarks[wristIdx]
  if (!s || !e || !w) return null
  if (s.visibility < VISIBILITY_THRESHOLD || e.visibility < VISIBILITY_THRESHOLD || w.visibility < VISIBILITY_THRESHOLD) return null

  return angleBetweenThreePoints(s, e, w)
}

/**
 * Shoulder tilt: angle of shoulder line from horizontal (degrees).
 * Positive = right shoulder higher, Negative = left shoulder higher.
 * Returns null if either shoulder visibility < threshold.
 */
export function computeShoulderTilt(landmarks: NormalizedLandmark[]): number | null {
  const L = landmarks[LANDMARK_INDICES.LEFT_SHOULDER]
  const R = landmarks[LANDMARK_INDICES.RIGHT_SHOULDER]
  if (!L || !R) return null
  if (L.visibility < VISIBILITY_THRESHOLD || R.visibility < VISIBILITY_THRESHOLD) return null

  return Math.atan2(R.y - L.y, R.x - L.x) * (180 / Math.PI)
}

/**
 * Hip rotation: angle of hip line from horizontal (degrees).
 * Same formula as shoulder tilt but for hips.
 * Returns null if either hip visibility < threshold.
 */
export function computeHipRotation(landmarks: NormalizedLandmark[]): number | null {
  const L = landmarks[LANDMARK_INDICES.LEFT_HIP]
  const R = landmarks[LANDMARK_INDICES.RIGHT_HIP]
  if (!L || !R) return null
  if (L.visibility < VISIBILITY_THRESHOLD || R.visibility < VISIBILITY_THRESHOLD) return null

  return Math.atan2(R.y - L.y, R.x - L.x) * (180 / Math.PI)
}

/**
 * Compute all three softball mechanics angles for a frame.
 */
export function computeFrameAngles(
  landmarks: NormalizedLandmark[],
  handedness: 'right' | 'left' = 'right'
): FrameAngles {
  return {
    elbowSlotDeg: computeElbowSlot(landmarks, handedness),
    shoulderTiltDeg: computeShoulderTilt(landmarks),
    hipRotationDeg: computeHipRotation(landmarks),
  }
}
```

**Create src/lib/pose/flags.ts**

```typescript
// src/lib/pose/flags.ts
// Rule-based mechanics issue flagging
// Ideal angle ranges sourced from softball biomechanics literature (LOW confidence)
// Sources: PMC11969493 (Fastpitch Softball Pitching Biomechanics), PMC8739590
// VALIDATE THESE RANGES WITH A COACH BEFORE SHIPPING

import { LANDMARK_INDICES, VISIBILITY_THRESHOLD } from './landmarks'
import type { NormalizedLandmark, MechanicsFlag } from '@/types/analysis'

// Claude's discretion: conservative thresholds flagging only clear outliers
// Use wide ranges for v1 — only flag obvious mechanics problems
export const IDEAL_RANGES = {
  elbowSlot: { min: 70, max: 110 },        // degrees — wider range to reduce false positives
  shoulderTilt: { min: -20, max: 20 },     // degrees from horizontal
  hipRotation: { min: 75, max: 105 },      // degrees — hip opening angle at contact
} as const

// Claude's discretion: 70% confidence threshold to filter low-visibility noise
export const FLAG_CONFIDENCE_THRESHOLD = 0.70

/**
 * Validates video framing quality using a heuristic.
 * Returns a warning string if framing is suboptimal, null if framing is acceptable.
 *
 * Side-view check: If left and right hip X-coordinates are within 15% of frame width,
 * the athlete is facing camera (not side-on), which degrades elbow slot accuracy.
 */
export function checkFramingQuality(
  landmarks: NormalizedLandmark[]
): string | null {
  const L = landmarks[LANDMARK_INDICES.LEFT_HIP]
  const R = landmarks[LANDMARK_INDICES.RIGHT_HIP]
  if (!L || !R) return null
  if (L.visibility < VISIBILITY_THRESHOLD || R.visibility < VISIBILITY_THRESHOLD) return null

  const hipSeparation = Math.abs(R.x - L.x)
  if (hipSeparation < 0.15) {
    return 'Suboptimal framing: athlete appears to be facing the camera rather than side-on. Side view is required for accurate elbow slot and hip rotation analysis.'
  }
  return null
}

/**
 * Flags mechanics issues based on computed angles and landmark visibility.
 * Confidence is derived from the average visibility of the relevant joint landmarks.
 * Only flags when confidence >= FLAG_CONFIDENCE_THRESHOLD.
 */
export function flagMechanics(
  elbowSlot: number | null,
  shoulderTilt: number | null,
  hipRotation: number | null,
  landmarks: NormalizedLandmark[]
): MechanicsFlag[] {
  const flags: MechanicsFlag[] = []

  // Arm landmark confidence
  const armLandmarks = [12, 14, 16].map(i => landmarks[i]?.visibility ?? 0)
  const armConf = armLandmarks.reduce((s, v) => s + v, 0) / armLandmarks.length

  // Hip landmark confidence
  const hipLandmarks = [23, 24].map(i => landmarks[i]?.visibility ?? 0)
  const hipConf = hipLandmarks.reduce((s, v) => s + v, 0) / hipLandmarks.length

  if (elbowSlot !== null && armConf >= FLAG_CONFIDENCE_THRESHOLD) {
    if (elbowSlot < IDEAL_RANGES.elbowSlot.min) {
      flags.push({
        issue: 'Elbow Drop',
        confidence: armConf,
        severity: 'warning',
        jointIndices: [LANDMARK_INDICES.RIGHT_ELBOW],
      })
    }
    if (elbowSlot > IDEAL_RANGES.elbowSlot.max) {
      flags.push({
        issue: 'Elbow Too High',
        confidence: armConf,
        severity: 'warning',
        jointIndices: [LANDMARK_INDICES.RIGHT_ELBOW],
      })
    }
  }

  if (shoulderTilt !== null && armConf >= FLAG_CONFIDENCE_THRESHOLD) {
    if (Math.abs(shoulderTilt) > IDEAL_RANGES.shoulderTilt.max) {
      flags.push({
        issue: 'Excessive Shoulder Tilt',
        confidence: armConf,
        severity: 'warning',
        jointIndices: [LANDMARK_INDICES.LEFT_SHOULDER, LANDMARK_INDICES.RIGHT_SHOULDER],
      })
    }
  }

  if (hipRotation !== null && hipConf >= FLAG_CONFIDENCE_THRESHOLD) {
    if (hipRotation < IDEAL_RANGES.hipRotation.min) {
      flags.push({
        issue: 'Early Hip Rotation',
        confidence: hipConf,
        severity: 'error',
        jointIndices: [LANDMARK_INDICES.LEFT_HIP, LANDMARK_INDICES.RIGHT_HIP],
      })
    }
  }

  return flags
}
```
  </action>
  <verify>
    <automated>npx tsc --noEmit 2>&1 | head -20</automated>
  </verify>
  <done>
    - src/lib/pose/landmarks.ts exports: ZONE_COLORS, LOWER_BODY_INDICES, VISIBILITY_THRESHOLD, LANDMARK_INDICES, drawSkeleton
    - src/lib/pose/angles.ts exports: angleBetweenThreePoints, computeElbowSlot, computeShoulderTilt, computeHipRotation, computeFrameAngles
    - src/lib/pose/flags.ts exports: IDEAL_RANGES, FLAG_CONFIDENCE_THRESHOLD, checkFramingQuality, flagMechanics
    - npx tsc --noEmit exits 0
  </done>
</task>

<task type="auto">
  <name>Task 2: MediaPipe Web Worker + install dependencies</name>
  <files>src/workers/pose-analyzer.worker.ts</files>
  <action>
**Step 1: Install dependencies**

```bash
npm install @mediapipe/tasks-vision comlink
```

Verify installation:
```bash
npm list @mediapipe/tasks-vision comlink | grep -E "(tasks-vision|comlink)"
```

**Step 2: Copy MediaPipe WASM assets to /public/mediapipe/**

The worker uses local WASM files to avoid CDN dependency in production (RESEARCH.md Pitfall 1).

```bash
# Create public directory for mediapipe assets
mkdir -p public/mediapipe/wasm

# Copy WASM files from node_modules
cp node_modules/@mediapipe/tasks-vision/wasm/vision_wasm_internal.js public/mediapipe/wasm/
cp node_modules/@mediapipe/tasks-vision/wasm/vision_wasm_internal.wasm public/mediapipe/wasm/
cp node_modules/@mediapipe/tasks-vision/wasm/vision_wasm_nosimd_internal.js public/mediapipe/wasm/
cp node_modules/@mediapipe/tasks-vision/wasm/vision_wasm_nosimd_internal.wasm public/mediapipe/wasm/
```

If the exact paths differ, check `node_modules/@mediapipe/tasks-vision/` for the wasm directory.

**Step 3: Download pose_landmarker_full.task model to /public/mediapipe/**

```bash
curl -L -o public/mediapipe/pose_landmarker_full.task \
  "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_full/float16/1/pose_landmarker_full.task"
```

**Step 4: Create src/workers/pose-analyzer.worker.ts**

IMPORTANT: This file must NOT use `@/` path aliases — Next.js cannot resolve `@/` aliases inside Web Workers. Import only npm packages directly.

```typescript
// src/workers/pose-analyzer.worker.ts
// MediaPipe PoseLandmarker running in a Web Worker via Comlink
// CRITICAL: No @/ alias imports — Worker bundle cannot resolve them

import * as Comlink from 'comlink'
import { PoseLandmarker, FilesetResolver } from '@mediapipe/tasks-vision'

let landmarker: PoseLandmarker | null = null

/**
 * Initialize MediaPipe PoseLandmarker using local WASM assets.
 * Must be called before detectOnImageBitmap.
 * Uses /public/mediapipe/wasm (local, avoids CDN dependency in production).
 */
async function init(): Promise<void> {
  const vision = await FilesetResolver.forVisionTasks('/mediapipe/wasm')
  landmarker = await PoseLandmarker.createFromOptions(vision, {
    baseOptions: {
      modelAssetPath: '/mediapipe/pose_landmarker_full.task',
      delegate: 'GPU',   // Falls back to CPU automatically if GPU unavailable
    },
    runningMode: 'IMAGE',   // IMAGE mode: analyze discrete frames, not continuous stream
    numPoses: 1,
    minPoseDetectionConfidence: 0.5,
    minPosePresenceConfidence: 0.5,
    minTrackingConfidence: 0.5,
  })
}

/**
 * Detect pose landmarks on a single video frame.
 * Caller passes an ImageBitmap created from a video element.
 * Returns the raw PoseLandmarkerResult landmarks array (33 landmarks).
 */
async function detectOnImageBitmap(bitmap: ImageBitmap): Promise<{
  landmarks: Array<Array<{ x: number; y: number; z: number; visibility: number }>>
}> {
  if (!landmarker) throw new Error('PoseLandmarker not initialized. Call init() first.')
  const result = landmarker.detect(bitmap)
  bitmap.close()  // free GPU/CPU memory immediately
  return {
    landmarks: result.landmarks as Array<Array<{ x: number; y: number; z: number; visibility: number }>>,
  }
}

Comlink.expose({ init, detectOnImageBitmap })
```

**Step 5: Add next.config.ts worker support**

Check next.config.ts. If it doesn't already have `experimental.workerThreads` or similar, no changes needed — Next.js 15 supports `new Worker(new URL(...), { type: 'module' })` natively without config changes.

Verify next.config.ts doesn't need modification (modern Next.js handles module workers automatically).
  </action>
  <verify>
    <automated>npx tsc --noEmit 2>&1 | head -20 && ls public/mediapipe/wasm/*.js 2>/dev/null | wc -l</automated>
  </verify>
  <done>
    - @mediapipe/tasks-vision and comlink appear in package.json dependencies
    - public/mediapipe/wasm/ directory contains at least 2 .js files (WASM modules)
    - public/mediapipe/pose_landmarker_full.task file exists (>1MB)
    - src/workers/pose-analyzer.worker.ts exports { init, detectOnImageBitmap } via Comlink.expose
    - No @/ alias imports in the worker file
    - npx tsc --noEmit exits 0
  </done>
</task>

</tasks>

<verification>
- src/lib/pose/landmarks.ts, angles.ts, flags.ts all exist
- src/workers/pose-analyzer.worker.ts uses Comlink.expose with { init, detectOnImageBitmap }
- Worker file contains NO @/ imports (grep: `from '@/` returns no matches in the worker file)
- public/mediapipe/wasm/ contains WASM assets
- public/mediapipe/pose_landmarker_full.task exists
- npx tsc --noEmit exits 0
</verification>

<success_criteria>
After Phase 2 Plan 02:
1. Three pure-function pose library files in src/lib/pose/ handle angle computation, flagging, and skeleton drawing
2. Web Worker in src/workers/ initializes MediaPipe from local WASM assets and exposes detectOnImageBitmap via Comlink
3. All MediaPipe WASM assets and model file are in public/mediapipe/
4. No CDN dependency at analysis time
5. TypeScript compiles clean
</success_criteria>

<output>
After completion, create `.planning/phases/02-ai-pose-analysis/02-02-SUMMARY.md`
</output>
